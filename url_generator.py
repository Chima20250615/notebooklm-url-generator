import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse

st.title("ğŸ“„ NotebookLMç”¨URLä¸€è¦§ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼")
st.write("æŒ‡å®šã—ãŸWebã‚µã‚¤ãƒˆå†…ã®ä¸‹å±¤ãƒšãƒ¼ã‚¸URLã‚’ä¸€è¦§åŒ–ã—ã¾ã™ï¼ˆNotebookLMç”¨ï¼‰")

# å…¥åŠ›ï¼šURL
base_url = st.text_input("å¯¾è±¡ã‚µã‚¤ãƒˆã®ãƒˆãƒƒãƒ—URLã‚’å…¥åŠ›ã—ã¦ã­", "https://example.com")

if st.button("URLä¸€è¦§ã‚’å–å¾—ï¼"):
    try:
        response = requests.get(base_url)
        soup = BeautifulSoup(response.text, 'html.parser')

        parsed_base = urlparse(base_url)
        domain = f"{parsed_base.scheme}://{parsed_base.netloc}"

        links = set()

        for tag in soup.find_all("a", href=True):
            href = tag["href"]
            full_url = urljoin(base_url, href)
            if full_url.startswith(domain):
                links.add(full_url)

        if links:
            st.success(f"{len(links)}ä»¶ã®URLã‚’å–å¾—ã—ã¾ã—ãŸğŸ‘‡")
            for link in sorted(links):
                st.text(link)
        else:
            st.warning("å†…éƒ¨ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    except Exception as e:
        st.error(f"å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
